{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifica√ß√£o de Imagens com CNN (PyTorch): C√£es vs. Gatos üê∂üê±\n",
    "\n",
    "**Objetivo:** Construir um modelo de Intelig√™ncia Artificial com Redes Neurais Convolucionais (CNN) para classificar imagens de cachorros e gatos, utilizando a biblioteca **PyTorch** como alternativa ao TensorFlow/Keras.\n",
    "\n",
    "**Dataset:** [Dogs vs. Cats - Kaggle](https://www.kaggle.com/c/dogs-vs-cats/data)\n",
    "\n",
    "**Estrutura do Projeto:**\n",
    "1.  **Prepara√ß√£o dos Dados:** Carregamento, organiza√ß√£o dos diret√≥rios, pr√©-processamento e aumento de dados com `torchvision`.\n",
    "2.  **Constru√ß√£o e Treinamento:** Defini√ß√£o da arquitetura da CNN em PyTorch, escrita do loop de treinamento manual e treinamento do modelo.\n",
    "3.  **Avalia√ß√£o e Testes:** An√°lise do desempenho com m√©tricas (precis√£o, recall, F1-score) e teste com novas imagens.\n",
    "4.  **Conclus√£o:** Resumo dos resultados e pr√≥ximos passos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepara√ß√£o dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Importa√ß√£o das Bibliotecas e Defini√ß√£o dos Caminhos\n",
    "\n",
    "Importamos as bibliotecas necess√°rias, incluindo `torch` e `torchvision`. A defini√ß√£o dos caminhos e a organiza√ß√£o dos arquivos permanecem as mesmas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Caminho para o diret√≥rio de treino original do Kaggle\n",
    "# ATEN√á√ÉO: Altere este caminho para o local onde voc√™ descompactou a pasta 'train'\n",
    "original_train_dir = './train/'\n",
    "\n",
    "# Caminho para o novo diret√≥rio base onde organizaremos os dados\n",
    "base_dir = './cats_vs_dogs_data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Cria√ß√£o dos Diret√≥rios e Separa√ß√£o dos Dados (70/15/15)\n",
    "\n",
    "Esta etapa √© id√™ntica √† vers√£o com TensorFlow. Criamos uma nova estrutura de diret√≥rios (`train`, `validation`, `test`) e movemos as imagens para seus respectivos locais, garantindo que `ImageFolder` do PyTorch possa encontr√°-las corretamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria o diret√≥rio base se n√£o existir\n",
    "if os.path.exists(base_dir):\n",
    "    shutil.rmtree(base_dir) # Remove o diret√≥rio se j√° existir para come√ßar do zero\n",
    "os.makedirs(base_dir)\n",
    "\n",
    "# Cria os subdiret√≥rios de treino, valida√ß√£o e teste\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "os.makedirs(train_dir)\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "os.makedirs(validation_dir)\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "os.makedirs(test_dir)\n",
    "\n",
    "# Cria os diret√≥rios de classes (gatos e cachorros) dentro de cada conjunto\n",
    "for dir_path in [train_dir, validation_dir, test_dir]:\n",
    "    os.makedirs(os.path.join(dir_path, 'cats'))\n",
    "    os.makedirs(os.path.join(dir_path, 'dogs'))\n",
    "\n",
    "# Nomes dos arquivos originais\n",
    "all_fnames = os.listdir(original_train_dir)\n",
    "cat_fnames = [fname for fname in all_fnames if fname.startswith('cat')]\n",
    "dog_fnames = [fname for fname in all_fnames if fname.startswith('dog')]\n",
    "\n",
    "# Fun√ß√£o para copiar as imagens para os novos diret√≥rios\n",
    "def copy_files(fnames, source_dir, dest_dirs):\n",
    "    for fname, dest in zip(fnames, dest_dirs):\n",
    "        src = os.path.join(source_dir, fname)\n",
    "        dst = os.path.join(dest, fname)\n",
    "        shutil.copyfile(src, dst)\n",
    "\n",
    "# Dividindo gatos (70-15-15)\n",
    "np.random.shuffle(cat_fnames)\n",
    "train_split = int(0.7 * len(cat_fnames))\n",
    "val_split = int(0.15 * len(cat_fnames))\n",
    "cat_train = cat_fnames[:train_split]\n",
    "cat_val = cat_fnames[train_split:train_split+val_split]\n",
    "cat_test = cat_fnames[train_split+val_split:]\n",
    "copy_files(cat_train, original_train_dir, [os.path.join(train_dir, 'cats')] * len(cat_train))\n",
    "copy_files(cat_val, original_train_dir, [os.path.join(validation_dir, 'cats')] * len(cat_val))\n",
    "copy_files(cat_test, original_train_dir, [os.path.join(test_dir, 'cats')] * len(cat_test))\n",
    "\n",
    "# Dividindo cachorros (70-15-15)\n",
    "np.random.shuffle(dog_fnames)\n",
    "train_split = int(0.7 * len(dog_fnames))\n",
    "val_split = int(0.15 * len(dog_fnames))\n",
    "dog_train = dog_fnames[:train_split]\n",
    "dog_val = dog_fnames[train_split:train_split+val_split]\n",
    "dog_test = dog_fnames[train_split+val_split:]\n",
    "copy_files(dog_train, original_train_dir, [os.path.join(train_dir, 'dogs')] * len(dog_train))\n",
    "copy_files(dog_val, original_train_dir, [os.path.join(validation_dir, 'dogs')] * len(dog_val))\n",
    "copy_files(dog_test, original_train_dir, [os.path.join(test_dir, 'dogs')] * len(dog_test))\n",
    "\n",
    "print(f\"Total de imagens de treino: {len(cat_train) + len(dog_train)}\")\n",
    "print(f\"Total de imagens de valida√ß√£o: {len(cat_val) + len(dog_val)}\")\n",
    "print(f\"Total de imagens de teste: {len(cat_test) + len(dog_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Pr√©-processamento e Carregamento dos Dados com `torchvision`\n",
    "\n",
    "Em vez do `ImageDataGenerator`, usamos `torchvision.transforms` para definir as opera√ß√µes de pr√©-processamento e aumento de dados. Em seguida, usamos `datasets.ImageFolder` para ler as imagens da nossa estrutura de diret√≥rios e `DataLoader` para criar lotes (batches) de dados de forma eficiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 150\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Transforma√ß√µes para o conjunto de treino (com Data Augmentation)\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.RandomRotation(40),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(), # Converte para tensor e normaliza para [0, 1]\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # Normaliza√ß√£o padr√£o da ImageNet\n",
    "])\n",
    "\n",
    "# Transforma√ß√µes para os conjuntos de valida√ß√£o e teste (sem Data Augmentation)\n",
    "val_test_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Criando os Datasets\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=train_transforms)\n",
    "validation_dataset = datasets.ImageFolder(validation_dir, transform=val_test_transforms)\n",
    "test_dataset = datasets.ImageFolder(test_dir, transform=val_test_transforms)\n",
    "\n",
    "# Criando os DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(f\"Classes encontradas: {train_dataset.classes}\")\n",
    "# ImageFolder atribui 'cats' a 0 e 'dogs' a 1 por ordem alfab√©tica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Constru√ß√£o e Treinamento de uma CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Cria√ß√£o da Rede Convolucional em PyTorch\n",
    "\n",
    "Em PyTorch, definimos o modelo como uma classe que herda de `nn.Module`. As camadas s√£o definidas no construtor `__init__`, e a ordem de execu√ß√£o (o *forward pass*) √© definida no m√©todo `forward`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            # Camada 1: Entrada (3, 150, 150)\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            # Camada 2\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            # Camada 3\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        self.fc_layers = nn.Sequential(\n",
    "            # O c√°lculo do tamanho de entrada √© 128 * (150/2/2/2) * (150/2/2/2) = 128 * 18 * 18 = 41472\n",
    "            nn.Linear(128 * 18 * 18, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 1) # Sa√≠da √∫nica para classifica√ß√£o bin√°ria\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc_layers(x)\n",
    "        return torch.sigmoid(x) # Aplicamos a sigmoide na sa√≠da\n",
    "\n",
    "# Instala a biblioteca para visualizar o resumo (opcional, mas √∫til)\n",
    "# !pip install torchinfo\n",
    "from torchinfo import summary\n",
    "\n",
    "model = SimpleCNN()\n",
    "summary(model, input_size=(BATCH_SIZE, 3, IMG_SIZE, IMG_SIZE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Treinamento do Modelo\n",
    "\n",
    "Definimos a fun√ß√£o de perda (`BCELoss` para entropia cruzada bin√°ria), o otimizador (`RMSprop`) e o dispositivo (GPU, se dispon√≠vel). Em seguida, escrevemos o loop de treinamento manual, que itera sobre as √©pocas e os lotes de dados, calcula a perda, faz a retropropaga√ß√£o (backpropagation) e atualiza os pesos do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Usando dispositivo: {device}\")\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.BCELoss() # Binary Cross-Entropy Loss\n",
    "optimizer = optim.RMSprop(model.parameters(), lr=1e-4)\n",
    "\n",
    "EPOCHS = 20\n",
    "\n",
    "history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # --- Treinamento ---\n",
    "    model.train() # Coloca o modelo em modo de treino\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device).float().view(-1, 1)\n",
    "        \n",
    "        optimizer.zero_grad() # Zera os gradientes\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward() # Backpropagation\n",
    "        optimizer.step() # Atualiza os pesos\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        predicted = (outputs > 0.5).float()\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "        \n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_acc = correct_train / total_train\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "\n",
    "    # --- Valida√ß√£o ---\n",
    "    model.eval() # Coloca o modelo em modo de avalia√ß√£o\n",
    "    running_val_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    with torch.no_grad(): # Desativa o c√°lculo de gradientes\n",
    "        for inputs, labels in validation_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device).float().view(-1, 1)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_val_loss += loss.item()\n",
    "            \n",
    "            predicted = (outputs > 0.5).float()\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "            \n",
    "    val_loss = running_val_loss / len(validation_loader)\n",
    "    val_acc = correct_val / total_val\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{EPOCHS}] | Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Gr√°ficos de Acur√°cia e Perda\n",
    "\n",
    "Plotamos as m√©tricas salvas durante o treinamento para visualizar o comportamento do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_range = range(EPOCHS)\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, history['train_acc'], label='Acur√°cia de Treino')\n",
    "plt.plot(epochs_range, history['val_acc'], label='Acur√°cia de Valida√ß√£o')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Acur√°cia de Treino e Valida√ß√£o')\n",
    "plt.xlabel('√âpocas')\n",
    "plt.ylabel('Acur√°cia')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, history['train_loss'], label='Perda de Treino')\n",
    "plt.plot(epochs_range, history['val_loss'], label='Perda de Valida√ß√£o')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Perda de Treino e Valida√ß√£o')\n",
    "plt.xlabel('√âpocas')\n",
    "plt.ylabel('Perda')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Avalia√ß√£o e Testes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Avalia√ß√£o do Desempenho no Conjunto de Teste\n",
    "\n",
    "Usamos o `test_loader` para fazer previs√µes no conjunto de teste. Coletamos todos os r√≥tulos e previs√µes para usar as fun√ß√µes do `scikit-learn` e gerar o relat√≥rio final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model(inputs).cpu()\n",
    "        \n",
    "        predicted = (outputs > 0.5).int()\n",
    "        \n",
    "        y_pred.extend(predicted.numpy().flatten())\n",
    "        y_true.extend(labels.numpy().flatten())\n",
    "\n",
    "print('\\nRelat√≥rio de Classifica√ß√£o:')\n",
    "print(classification_report(y_true, y_pred, target_names=['cats', 'dogs']))\n",
    "\n",
    "print('\\nMatriz de Confus√£o:')\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Teste com Novas Imagens\n",
    "\n",
    "Criamos uma fun√ß√£o que carrega uma nova imagem, aplica as mesmas transforma√ß√µes do conjunto de teste e usa o modelo treinado para fazer uma previs√£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_new_image(image_path, model, device):\n",
    "    model.eval()\n",
    "    \n",
    "    # Carrega e pr√©-processa a imagem\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    input_tensor = val_test_transforms(image) # Usa as mesmas transforms da valida√ß√£o\n",
    "    input_batch = input_tensor.unsqueeze(0) # Cria um batch com uma √∫nica imagem\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(input_batch.to(device))\n",
    "        prediction_prob = output.item()\n",
    "    \n",
    "    # Exibe a imagem e o resultado\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    class_names = train_dataset.classes\n",
    "    if prediction_prob > 0.5:\n",
    "        # Classe 1 (dogs)\n",
    "        plt.title(f'Previs√£o: {class_names[1]} ({prediction_prob:.2f})')\n",
    "    else:\n",
    "        # Classe 0 (cats)\n",
    "        plt.title(f'Previs√£o: {class_names[0]} ({1 - prediction_prob:.2f})')\n",
    "    plt.show()\n",
    "\n",
    "# Crie o diret√≥rio se n√£o existir\n",
    "new_images_dir = 'novas_imagens'\n",
    "os.makedirs(new_images_dir, exist_ok=True)\n",
    "print(f\"Por favor, adicione suas imagens de teste na pasta '{new_images_dir}' e atualize a lista abaixo.\")\n",
    "\n",
    "# ATEN√á√ÉO: Adicione aqui os caminhos para as suas imagens de teste\n",
    "new_images_paths = [\n",
    "    # Ex: 'novas_imagens/meu-gato.jpg',\n",
    "    # Ex: 'novas_imagens/cachorro-vizinho.png'\n",
    "]\n",
    "\n",
    "if not new_images_paths:\n",
    "    print(\"\\nNenhuma imagem nova para testar. Adicione os caminhos √† lista 'new_images_paths'.\")\n",
    "else:\n",
    "    for img_path in new_images_paths:\n",
    "        if os.path.exists(img_path):\n",
    "            predict_new_image(img_path, model, device)\n",
    "        else:\n",
    "            print(f\"Arquivo n√£o encontrado: {img_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Conclus√£o Final\n",
    "\n",
    "Neste exerc√≠cio, constru√≠mos um pipeline de classifica√ß√£o de imagens utilizando **PyTorch**.\n",
    "\n",
    "**Resumo dos Resultados:**\n",
    "* **Prepara√ß√£o dos Dados:** A combina√ß√£o de `torchvision.transforms`, `datasets.ImageFolder` e `DataLoader` provou ser uma maneira robusta e eficiente de carregar, pr√©-processar e aumentar os dados de imagem para o treinamento.\n",
    "\n",
    "* **Modelo CNN:** A defini√ß√£o do modelo como uma classe `nn.Module` em PyTorch √© clara e estruturada. O loop de treinamento manual, embora mais verboso que o `.fit()` do Keras, nos deu total controle sobre cada etapa do processo, desde a atualiza√ß√£o dos gradientes at√© a avalia√ß√£o em tempo real.\n",
    "\n",
    "* **Avalia√ß√£o:** O modelo alcan√ßou um desempenho s√≥lido no conjunto de teste, demonstrando que a arquitetura e a estrat√©gia de treinamento foram eficazes. O controle granular do PyTorch permite um monitoramento preciso do desempenho em cada etapa.\n",
    "\n",
    "**Compara√ß√£o e Pr√≥ximos Passos:**\n",
    "A principal diferen√ßa em rela√ß√£o √† abordagem com TensorFlow/Keras foi a necessidade de escrever o loop de treinamento e valida√ß√£o manualmente. Isso oferece grande flexibilidade para cen√°rios de pesquisa ou implementa√ß√µes customizadas, enquanto Keras oferece uma API de mais alto n√≠vel para prototipagem r√°pida.\n",
    "\n",
    "Os pr√≥ximos passos s√£o os mesmos, independentemente do framework:\n",
    "1.  **Ajuste de Hiperpar√¢metros:** Testar diferentes otimizadores (`Adam`), taxas de aprendizado e arquiteturas.\n",
    "2.  **Transfer Learning:** A maior melhoria viria do uso de uma rede pr√©-treinada do `torchvision.models` (como `resnet50` ou `mobilenet_v2`), que √© uma pr√°tica padr√£o em vis√£o computacional para alcan√ßar alta acur√°cia com menos dados e tempo de treinamento."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
